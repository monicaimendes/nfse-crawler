# NFSE Crawler (work in progress)

## ğŸ“Œ Description
This project is designed to crawl the Brazil national invoice website. It runs automatically on a daily basis, retrieving information about invoices received or sent that day for my company.
The collected data is then sent to my email once a day.

## ğŸ“ Project Structure
```
/nfse-crawler
â”‚â”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ daily_routine.yml   # GitHub Actions workflow file for automation
â”‚
â”‚â”€â”€ scraper/                     # Main folder containing the scraping code
â”‚   â”‚â”€â”€ config.py                # Dynamo and SNS config
â”‚   â”‚â”€â”€ database.py              # Database management
â”‚   â”‚â”€â”€ insert_data.py           
â”‚   â”‚â”€â”€ main.py                  # Calls the scraper
â”‚   â”‚â”€â”€ nacional.py              # Scraper code
â”‚
â”‚â”€â”€ .gitignore                  
â”‚â”€â”€ requirements.txt             # List of dependencies required for the project
```
